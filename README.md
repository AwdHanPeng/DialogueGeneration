# DialogueGeneration
The is another expriment in dialogue dataset used Transformer.

references:
Attention Is All Your Need

http://nlp.seas.harvard.edu/2018/04/03/attention.html

In this project, I realized a chit-bot used Transformer model.
Part of the code about model architecture comes from the blog in the references list.

The dataset is crawlled from WeiBo, and it is a very big dataset.
So this performance is pretty well.

Most detail and case study can be seen in report folder.

Thanks!!

